{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf01f83-7f3a-42e0-8eb4-a4ff6124c3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.1.24-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.70.0-cp312-cp312-macosx_10_14_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-macosx_12_0_arm64.whl (239.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.1.24-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp312-cp312-macosx_10_14_universal2.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl (405 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.0-cp312-cp312-macosx_11_0_arm64.whl (335 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/Users/tim/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/Users/tim/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.1.24 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 keras-3.8.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7209d69b-da7d-4ce8-ab02-943caad903ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751b293-fecd-4c8f-b286-34949cdb4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Load and Process JSON Data\n",
    "# -------------------------------\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512dae2-ec38-4b08-8c95-544c92f6a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 2. Tokenizer for Math & Story Problems\n",
    "# -------------------------------\n",
    "def preprocess_data(json_data):\n",
    "    math_problems = [item['math'] for item in json_data if 'math' in item]\n",
    "    story_problems = [item['story'] for item in json_data if 'story' in item]\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(math_problems + story_problems)\n",
    "\n",
    "    math_sequences = tokenizer.texts_to_sequences(math_problems)\n",
    "    story_sequences = tokenizer.texts_to_sequences(story_problems)\n",
    "\n",
    "    max_length = max(len(seq) for seq in math_sequences + story_sequences)\n",
    "    math_sequences = pad_sequences(math_sequences, maxlen=max_length, padding='post')\n",
    "    story_sequences = pad_sequences(story_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "    return math_sequences, story_sequences, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf601a-aafb-4b90-bd65-a9525009959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 3. Drake's Formula for Numerical Processing\n",
    "# -------------------------------\n",
    "def apply_drakes_formula(data):\n",
    "    \"\"\"\n",
    "    Applies Drake's Formula-style weighting to numerical data.\n",
    "    This is just an initial formula structure that can be adjusted.\n",
    "    \"\"\"\n",
    "    num_factors = len(data[0]) if len(data) > 0 else 1\n",
    "    multiplier = 1.0 + (num_factors * 0.1)\n",
    "    \n",
    "    scaled_data = np.array(data) * multiplier\n",
    "    normalization_factor = np.max(scaled_data)\n",
    "    return scaled_data / normalization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950fc82-7586-48de-b5a6-3cf9bc1147d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Neural Network Model for Predictions\n",
    "# -------------------------------\n",
    "def build_model(input_dim, output_dim=1):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=input_dim, output_dim=64, input_length=100),  # Token embedding layer\n",
    "        LSTM(64, return_sequences=True),\n",
    "        LSTM(32),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(output_dim, activation='sigmoid')  # Binary prediction output\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf0e90-4d70-47ff-b21a-edf1fbe86bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 5. Training the Model\n",
    "# -------------------------------\n",
    "def train_model(json_file):\n",
    "    json_data = load_json_data(json_file)\n",
    "    math_data, story_data, tokenizer = preprocess_data(json_data)\n",
    "\n",
    "    # Apply Drake’s Formula to math data\n",
    "    math_data_scaled = apply_drakes_formula(math_data)\n",
    "\n",
    "    # Splitting into training & validation sets\n",
    "    split_idx = int(len(math_data_scaled) * 0.8)\n",
    "    x_train, x_val = math_data_scaled[:split_idx], math_data_scaled[split_idx:]\n",
    "    y_train, y_val = np.ones(len(x_train)), np.ones(len(x_val))  # Placeholder labels for now\n",
    "\n",
    "    # Train model\n",
    "    model = build_model(input_dim=len(tokenizer.word_index) + 1)\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131a89a-eff9-409e-8f92-65ddf6041e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 6. Save & Load Model Functions\n",
    "# -------------------------------\n",
    "def save_model(model, tokenizer, model_path=\"ai_model.h5\", tokenizer_path=\"tokenizer.json\"):\n",
    "    model.save(model_path)\n",
    "    with open(tokenizer_path, 'w') as f:\n",
    "        json.dump(tokenizer.word_index, f)\n",
    "\n",
    "def load_saved_model(model_path=\"ai_model.h5\", tokenizer_path=\"tokenizer.json\"):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    with open(tokenizer_path, 'r') as f:\n",
    "        word_index = json.load(f)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.word_index = word_index\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23841a57-2b7d-4ede-96e0-837ca11db9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 7. Prediction Function\n",
    "# -------------------------------\n",
    "def predict(input_text, model, tokenizer):\n",
    "    sequence = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=100, padding='post')\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return \"Positive\" if prediction[0][0] > 0.5 else \"Negative\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d400b7c-7773-42ec-84f6-4f4f43c3bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# RUN TRAINING\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = \"training_data.json\"  # Change this to the actual file path\n",
    "    model, tokenizer = train_model(json_file)\n",
    "    save_model(model, tokenizer)\n",
    "\n",
    "    # Test prediction\n",
    "    test_input = \"If a train is traveling at 60mph and it departs at 3:00 PM...\"\n",
    "    print(\"Prediction:\", predict(test_input, model, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
